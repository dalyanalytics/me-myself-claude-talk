---
title: "Me, Myself & Claude"
subtitle: "How I Leverage AI-Assisted Development to Scale My Solo R-based Data Science Consultancy"
author: "Jasmine Daly<br>Principal Consultant & Founder<br>Daly Analytics"
date: "Wednesday, November 12, 2025"
format:
  revealjs:
    theme: [simple, theme/daly-analytics.scss]
    transition: slide
    slide-number: true
    chalkboard: true
    preview-links: auto
    code-line-numbers: false
    highlight-style: github
    logo: images/sunset.png
---

## Introduction {.center}

**AI-Assisted Development in R**

A journey of staying in your lane while scaling your impact!

::: {.notes}
Hello everyone! Today I want to share my experience integrating AI into my R development workflow - not as a replacement for expertise, but as a strategic force multiplier.
:::

---

## Who Am I? {.smaller}

- R Developer & Data Scientist since 2014
- Maintainer of {shinyLP}, {ttbbeer}, {avilistr}^, {shinyfa}^
- Running a *mostly* solo consultancy focused on delivering solutions with data science, analytics & AI 
- Building Shiny applications, interactive dashboards, and data automation pipelines


::: {.notes}
To level-set everyone and provide some context: I'm a mom of 2 young kids with limited time resources. I'm also an active Volunteer in my local community.

I'm managing both the technical (writing code) and business sides (doing discovery/sales calls) of my practice. I just recently onboarded a subcontractor this Summer that provides adhoc shiny development support, which has been wonderful in delegating tasks to them. 
:::

---

## üîë Moving Beyond 'Vibe Coding' {.smaller}

::: columns
::: {.column width="60%"}
**Words matter. Let's reframe the conversation.**

::: {.incremental}
- **"Vibe Coding"** ‚Üí Implies reckless, hope-based development
- **"Vibe Engineering"** ‚Üí Intentional, accountable AI-assisted development
- **"I'm adding a new (agentic) tool to my tool box"** ‚Üí Honest acknowledgment of exploration of this phase of hypergrowth and learning
:::
:::

::: {.column width="40%"}
![](images/vibes.jpeg){width=100%}
:::
:::

::: {.notes}
Credit to Christopher Fitkin's LinkedIn post on "vibe engineering" which really resonated with me.

One of the key takeaways of this entire talk is to reframe our language around how we talk about AI-assisted coding. "Vibe Coding" - while often funny - really diminishes our impact and the capacity for others to understand our lived experience as software developers.

It also does a disservice to our community when it comes to advocating for democratizing our field for diverse participants while also trying to emphasize the real complexity around ethics, governance, and professional responsibility.

The distinction Fitkin makes is critical: "vibe coding" suggests careless dependency where you hope AI outputs work. "Vibe engineering" means experienced developers intentionally leveraging AI tools while maintaining full accountability.

This isn't about replacing human expertise - it's about experienced engineers guiding AI tool adoption as an enhancement to craft, not a substitute for professional judgment.

**The Reality:** We're in an **exploratory phase**. There are no settled best practices yet. Making mistakes is part of professional growth. But you remain **fully accountable** for the outcome.

tl;dr: it's hard to say things are easy, give people the confidence and tools and then back track and say 'well that's not serious data science" so everything you 'vibe coded' shouldnt be used.
:::

# Part 1: Strategic Thinking Unlocked for Greater Community Contributions

## The Mental Bandwidth Shift {.smaller}

<div style="display: flex; justify-content: center; align-items: center; gap: 40px; padding: 20px 10px; max-width: 100%; margin: 0 auto;">

<div style="text-align: center; flex: 1; max-width: 280px;">
<h3 style="font-size: 1.6em; margin-bottom: 15px; color: #404041; font-weight: bold;">Before AI</h3>

<div style="background: #6A94C9; height: 340px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1.2em; font-weight: bold; color: white; line-height: 1.3;">Client Dev</div>
<div style="font-size: 2em; font-weight: bold; color: white; margin-top: 5px;">85%</div>
</div>

<div style="background: #D68A93; height: 60px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); overflow: visible;">
<div style="font-size: 0.95em; font-weight: bold; color: white; line-height: 1.2;">Biz Dev 15%</div>
</div>
</div>

<div style="text-align: center; flex: 0 0 auto;">
<div style="font-size: 4em; color: #F9B397; font-weight: bold; line-height: 1;">‚Üí</div>
<div style="font-size: 1em; color: #404041; font-weight: bold; margin-top: 5px; line-height: 1.2;">AI Unlocks<br>15%</div>
</div>

<div style="text-align: center; flex: 1; max-width: 280px;">
<h3 style="font-size: 1.6em; margin-bottom: 15px; color: #404041; font-weight: bold;">With AI</h3>

<div style="background: #6A94C9; height: 280px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1.2em; font-weight: bold; color: white; line-height: 1.3;">Client Dev</div>
<div style="font-size: 2em; font-weight: bold; color: white; margin-top: 5px;">70%</div>
</div>

<div style="background: #D68A93; height: 100px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Biz Dev</div>
<div style="font-size: 1.6em; font-weight: bold; color: white; margin-top: 3px;">25%</div>
</div>

<div style="background: #AD92B1; min-height: 40px; height: 40px; display: flex; flex-direction: column; justify-content: center; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); padding: 5px 10px;">
<div style="font-size: 0.85em; font-weight: bold; color: white; line-height: 1.1;">Community 5%</div>
</div>
</div>

</div>

::: {.notes}
This visualization shows the most fundamental shift that AI-assisted development has created for me as a solo consultant.

**Before AI:** 85% of my mental energy and time went to client development work. That's writing code, debugging, implementing features, wrestling with syntax. Only 15% went to business development‚Äîproposals, networking, marketing, financial planning. There was no room for anything else.

**The AI Impact:** AI assistance freed up 15% of my cognitive capacity. Not by making me work less, but by making the technical work less mentally taxing. I'm still doing client dev, but it drops from 85% to 70% because tasks that used to take hours (debugging YAML, googling package syntax, scaffolding boilerplate) now take minutes.

**The Reallocation:** That 15% didn't disappear‚Äîit got redistributed:
- **Business Development grew from 15% to 25%** - Now I can actually do proper business operations: automated systems, financial planning, strategic thinking about where the consultancy is going.
- **Community Contribution became possible at 5%** - Before AI, open source contributions felt like a luxury I couldn't afford. Now I have capacity for packages like {shinyfa} and {avilistr}, conference talks like this one, and community engagement.

**The Key Insight:** This isn't about working more hours. It's about cognitive load. When AI handles the syntax details, documentation lookups, and boilerplate generation, my brain has room for strategic thinking, creative problem-solving, and community engagement. That's the mental bandwidth shift.

This slide sets up everything that follows in the talk‚Äîall four parts are enabled by this fundamental reallocation of cognitive capacity.
:::

---


## What Mental Bandwidth Buys You

::: {.incremental}
- **Better Biz Ops:** Improving my systems to be automated and Standardized
- **Financial Clarity:** Time to understand cash flow, pricing strategy, and profitability
- **Relationship Building:** Networking, content creation, community engagement
- **Creative Space:** Room to think about what *could* be built, not just what *must* be built
:::

::: {.notes}
The mental bandwidth shift from 85% client dev to 70% client dev freed up 15% of my cognitive capacity. That 15% doesn't sound like much, but it's transformational.

**Better Biz Ops:** I now have time to build automated systems and standardized processes. Proposals, contracts, invoicing - things that used to be rushed now have proper templates and workflows.

**Financial Clarity:** Understanding cash flow, pricing strategy, and profitability isn't a "someday" task anymore. I can make strategic financial decisions instead of reactive ones.

**Relationship Building:** Networking isn't just attending events - it's consistent content creation, community engagement, and showing up in ways that build long-term relationships.

**Creative Space:** This is the big one. I now have room to think about what *could* be built, not just what *must* be built. That's where packages like {shinyfa} come from - tapping into real and persistent problems and creative exploration that serves the community.

Before AI: I was always feeling behind on the business side, constantly in reactive mode.

After AI: More strategic, more sustainable, and more creative. I'm building a business, not just executing projects.
:::

---

## The {shinyfa} Package <img src="images/shinyfa.png" width="80" style="vertical-align: middle; margin-left: 10px;"> {.smaller}

::: columns
::: {.column width="45%"}

<div style="display: flex; flex-direction: column; gap: 15px; margin-top: 20px;">

<div style="background: #6A94C9; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Client Problem</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Months to navigate large Shiny app</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">‚Üì</div>

<div style="background: #AD92B1; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Quick Script</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Analyze file structure</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">‚Üì</div>

<div style="background: #D68A93; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">CRAN Package</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Community tool</div>
</div>

</div>

::: {.fragment}
<div style="text-align: center; margin-top: 15px; font-size: 0.9em;">
**Before AI:** "Nice someday project."

**With AI:** Built and released in weeks.
</div>
:::
:::

::: {.column width="55%"}
**Output:**

| file_name | type | name |
|-----------|------|------|
| ui.R | input | selectInput |
| ui.R | output | plotOutput |
| server.R | reactive | filtered_data |
| server.R | render | renderPlot |
| modules/map.R | input | sliderInput |
| modules/map.R | render | renderLeaflet |

::: {.fragment}
Catalog of render functions, reactive functions, inputs, and file relationships across your entire Shiny app.
:::
:::
:::

::: {.notes}
This is a perfect example of how AI freed up mental bandwidth for creative work.

**The Flowchart (Left):**
- **Client Problem:** I was contracted to work on a large, complex Shiny app for a conservation nonprofit. It took me MONTHS to get comfortable in their repo - understanding which files did what, how the reactive dependencies flowed, where inputs and outputs were defined.
- **Quick Script:** About halfway through, I realized: "I'm a Shiny developer. There has to be a better way to systematically analyze app structure." So I wrote a one-off script to catalog render functions, reactive functions, inputs, and file relationships.
- **CRAN Package:** That script was so useful that I kept refining it. Then I thought - "Other developers face this same problem." With Claude's help, I generalized those functions, added documentation, built tests, and packaged it up as {shinyfa}.

**The Output Table (Right):** The result is a dataframe that gives you a complete map of your app's structure. Each row represents a reactive element: inputs, outputs, reactive expressions, and render functions. You can see which file they're in, what type they are, their name, and how they connect.

**Why This Matters:** For that conservation nonprofit project, this would have been transformational during onboarding. Instead of manually searching through dozens of files asking "where is the species input used?", you get a structured dataset you can query: `file_analysis %>% filter(input_id == "species")` and instantly see everywhere it's referenced.

**The Power:** You can answer questions like:
- "Show me all render functions in the modules folder"
- "Which files have reactive expressions?"
- "What outputs don't have corresponding render functions?" (potential bugs!)
- "Map the flow from this input to its output"

**The Timeline:** The entire process from "useful script" to "published package" took weeks, not months. Without AI assistance, this would have stayed as a one-off script on my hard drive, or been a "someday" project I never got to.

**The Impact:** This is what mental bandwidth buys you: the ability to take a client problem, generalize it, and contribute a tool back to the community - all without sacrificing your business. {shinyfa} solves a problem I experienced repeatedly - onboarding developers to complex Shiny apps. It would have saved me weeks during that client engagement.
:::

---

## The {avilistr} Package <img src="images/avilistr.png" width="80" style="vertical-align: middle; margin-left: 10px;"> {.smaller}

::: columns
::: {.column width="45%"}
<div style="display: flex; flex-direction: column; gap: 15px; margin-top: 20px;">

<div style="background: #AD92B1; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">New Hobby</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Started birding, found taxonomy in Excel</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">‚Üì</div>

<div style="background: #6A94C9; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Wrap Excel</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">11k+ species, Cornell Lab codes</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">‚Üì</div>

<div style="background: #D68A93; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">CRAN Package</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">In a weekend</div>
</div>

</div>

::: {.fragment}
<div style="text-align: center; margin-top: 20px; font-size: 0.9em;">
**Before AI:** "Nice to have, not crucial."

**With AI:** Published with docs in a weekend.
</div>
:::
:::

::: {.column width="55%"}
**Output:**
```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 5

library(ggplot2)
library(dplyr)
library(avilistr)

data(avilist_2025)

order_diversity <- avilist_2025 %>%
  filter(Taxon_rank == "species") %>%
  count(Order, sort = TRUE) %>%
  filter(n > 100)

ggplot(order_diversity, aes(x = reorder(Order, n), y = n)) +
  geom_col(fill = "#6A94C9") +
  coord_flip() +
  labs(title = "Bird Diversity by Order",
       subtitle = "Over 100 species",
       x = NULL, y = "Number of Species") +
  theme_minimal(base_size = 11)
```

::: {.fragment}
**Passeriformes:** 6,700+ species (over half of all birds!)
:::
:::
:::

::: {.notes}
**The Personal Story:** I started birding in 2025 - a new hobby outside of tech. I discovered the AviList Global Avian Checklist (unified global bird taxonomy) in Excel format. For R users working with bird data - especially integrating with eBird through {rebird} - having this taxonomy in R makes workflows cleaner.

**The Flowchart (Left):**
- **New Hobby:** Started birding, discovered the Excel taxonomy
- **Wrap Excel:** Converted 11,131 species + Cornell Lab codes to R
- **CRAN Package:** Published in less than a week with comprehensive docs

**The Visualization (Right):** Shows bird diversity by taxonomic order. Passeriformes (perching birds/songbirds) dominates with 6,700+ species - over 60% of all bird species. This kind of exploratory analysis is what R birders want to do.

**The Technical Reality:** Total honesty - this wasn't groundbreaking. I took a published Excel sheet and wrapped it into an R package. The Excel conversion was straightforward, not a heavy lift.

**Where AI Made the Difference:** The real work was documentation. The getting-started vignette shows practical workflows: exploring species, finding specific groups (194 thrush species), comparing taxonomies, connecting to eBird observations. Claude helped structure vignettes and write clear examples.

**The Timeline:** With AI, I focused on "what examples help birders?" vs. getting bogged down in documentation tedium. From idea to CRAN with comprehensive docs: less than a week.

**The Bigger Message:** Lowering the barrier to contribution. You don't need technical complexity to add value. Sometimes it's "take this useful thing in the wrong format and make it accessible" - and with AI, doing that WELL (with good docs!) becomes feasible in days, not months.

Finding common ground in open source: birding + R + accessibility = a contribution I'm genuinely proud of.
:::

---

## üîë The Creative Multiplier

AI assistance doesn't just save time on what you were already doing.

**It unlocks what you weren't doing at all:**

- Open source contributions (like shinyfa and avilistr)
- Writing better tests and documentation
- Building developer tools that solve real problems
- Package development with proper structure
- Community engagement and knowledge sharing

::: {.notes}
*Side note: ChatGPT is great for hex sticker design and branding ideas!*
:::

::: {.notes}
{ttbbeer} my first package was released July 2016 and 
{shinyLP} my second package was first released on September 2016. The next CRAN package i released was {avilistr} in June 2025. That's 8 years 9 months (September 16, 2016‚Äâ‚Äì‚ÄâJune 17, 2025)
:::


# Part 2: Saying Yes to Bigger & Funner Problems

## Optimizing for Professional Joy

```{r}
#| echo: false
#| eval: true
#| fig-width: 11
#| fig-height: 8

library(ggplot2)

# Create data for four quadrants representing professional joy components
components <- data.frame(
  xmin = c(0, 1, 0, 1),
  xmax = c(1, 2, 1, 2),
  ymin = c(1, 1, 0, 0),
  ymax = c(2, 2, 1, 1),
  label = c("Client\nWork", "Technical\nGrowth", "Life\nBalance", "Community"),
  color = c("#6A94C9", "#AD92B1", "#F9B397", "#D68A93"),
  x_label = c(0.5, 1.5, 0.5, 1.5),
  y_label = c(1.5, 1.5, 0.5, 0.5)
)

ggplot(components) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = color),
            alpha = 0.4, color = "white", linewidth = 4) +
  geom_text(aes(x = x_label, y = y_label, label = label),
            size = 8, fontface = "bold", color = "#404041") +
  annotate("point", x = 1, y = 1, size = 35, color = "#404041", alpha = 0.1, shape = 19) +
  annotate("text", x = 1, y = 1, label = "Professional\nJoy",
           size = 10, fontface = "bold", color = "#404041") +
  scale_fill_identity() +
  coord_fixed(ratio = 1, xlim = c(-0.1, 2.1), ylim = c(-0.1, 2.1)) +
  theme_void() +
  theme(plot.margin = margin(20, 20, 20, 20))
```

::: {.notes}
This is the core philosophy that drives everything in Part 2. I'm running a solo consultancy, and I could optimize for different things‚Äîmaximum revenue, maximum number of clients, or rapid business growth. But that's not what I'm after.

**The Venn Diagram:** Professional joy sits at the intersection of four overlapping areas:

**Client Work (Blue):** Values-aligned clients‚Äînonprofits, social impact organizations, NGOs. These are organizations doing important work in the world, often with limited resources. High personal interaction and deep relationships, not transactional projects. Quality over quantity‚ÄîI'd rather work with 5 clients I'm deeply invested in than 20 clients where I'm just checking boxes.

**Technical Growth (Purple):** Challenging problems that expand my R expertise. Working on problems that challenge me technically‚Äîlearning new packages, exploring new approaches, building expertise in data engineering, automation, and infrastructure. This keeps the work interesting and valuable.

**Community (Pink):** Professional development through community engagement‚Äîspeaking at conferences like this one, contributing open source packages ({shinyfa}, {avilistr}), participating in the R community, continuous learning. These activities don't directly generate revenue, but they're essential to professional satisfaction and long-term growth.

**Life Balance (Orange):** Not sacrificing home life for business growth. I'm a solo consultant, not a startup founder trying to build a unicorn. I have a life outside of work that matters‚Äîfamily, hobbies, health. Sustainable consulting means not burning out.

**Professional Joy (Center):** Where all four overlap. This is the sweet spot where I'm doing meaningful client work, growing technically, contributing to community, and maintaining life balance.

**The AI Advantage:** Here's where AI becomes transformative. It doesn't just save me time‚Äîit gives me the capacity to be *selective*. I can say YES to the projects that bring professional joy and NO to the ones that don't, because AI assistance means I'm not constantly capacity-constrained. I can take on challenging technical problems without sacrificing quality or work-life balance.

This philosophy sets up everything that follows in Part 2. The technical skills and workflows I'm about to share aren't about doing more work‚Äîthey're about doing the *right* work, with the *right* clients, in a way that's sustainable and joyful.
:::

---

## The Growth Question

Before AI-assisted development, my filter for new projects was:

> "Can I build this in a reasonable timeframe with my current skillset given my existing client workload?"

::: {.notes}
**This often meant saying NO to:**

- Projects requiring unfamiliar R packages 
- Learning new techniques to support the project
- Interesting client opportunities
:::
---

## The New Filter

With AI-assisted development, the question became:

> "Can I can deeply understand the desired outcome based on the contraints? I'm pretty sure I can build this"

::: {.notes}
**Now I can say YES to:**

- Pipeline development and automation
- Data engineering workflows
- Complex hosting solutions
- Technologies outside my comfort zone but within my skillset
:::
---

## Claude Code as My Coding Partner {.smaller}

**The Mental Model:**

::: {.incremental}
- **You are the manager** - Setting direction, making architectural decisions
- **Claude is your senior developer** - Implementing solutions, handling boilerplate
- **Human in the loop** - Technical leadership stays with you
:::

::: {.fragment}
This isn't about replacing your skills‚Äîit's about **amplifying your capacity** to take on bigger, more interesting problems.
:::

::: {.notes}
This is the critical mental model shift. You're not becoming dependent on AI or losing your technical skills. You're establishing a working relationship where you maintain technical leadership.

**You are the manager:** You understand the client requirements, make architectural decisions, choose the technology stack, and own the final deliverable.

**Claude is your senior developer:** It handles implementation details, writes boilerplate, suggests approaches, and speeds up the coding process.

**Human in the loop:** You review everything, test rigorously, and course-correct when Claude goes off track. Your technical judgment is what ensures quality.

This model lets you say YES to bigger projects while maintaining the quality and technical ownership that makes you valuable to clients.
:::

---

## Client Example: Using GitHub Actions For Data Orchestration {.smaller}

::: columns
::: {.column width="45%"}
**The Client Challenge:**

- Multi-client dashboard infrastructure (50+ clients)
- Each client needs automated data refresh (daily/weekly/monthly)
- Scheduled pipelines, testing workflows, deployment triggers
- Cross-repo coordination

::: {.fragment}
**Built comprehensive system in days, not weeks.**
:::
:::

::: {.column width="55%"}
```yaml
name: Data Orchestrator
on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM UTC
  workflow_dispatch:

jobs:
  orchestrate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup R
        uses: r-lib/actions/setup-r@v2

      - name: Process clients based on schedule
        run: |
          Rscript scripts/orchestrator.R
        env:
          GITHUB_TOKEN: ${{ secrets.PAT_TOKEN }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
```

::: {.fragment}
**I understand what it does. Claude wrote the syntax.**
:::
:::
:::

::: {.notes}
This is a real example from my Meet the Moment client work. They needed an enterprise-grade data orchestration system to manage 50+ client dashboards, each with different refresh schedules.

**The Client Challenge (Left):**
- **50+ clients:** Each with their own dashboard
- **Different schedules:** Daily, weekly, monthly, quarterly refreshes
- **Complex infrastructure:** Scheduled pipelines, testing workflows, deployment triggers
- **Cross-repo coordination:** Repository dispatch events to trigger builds in separate repos

**The YAML (Right):** This is actual code from the system. Look at what's happening:
- **Scheduled trigger:** `cron: '0 6 * * *'` runs daily at 6 AM UTC, processes all clients based on their individual refresh schedules
- **Manual trigger:** `workflow_dispatch` allows testing on demand
- **R integration:** Sets up R environment, installs packages, runs the orchestrator script
- **Secrets management:** Properly uses GitHub secrets for cross-repo operations and database access

**The Key Insight:** I didn't need to memorize GitHub Actions syntax. I needed to understand the architecture‚Äîwhat needs to happen, when, and why. Claude Code handled translating that understanding into correct YAML.

**My Approach:** I understood the architecture (what needed to happen and when), but I didn't want to spend weeks becoming a GitHub Actions expert.

**Claude's Role:** Generated the YAML workflows, helped set up the orchestrator pattern, created the manual testing workflows, and built the configuration-driven scheduling system.

**My Role:** Designed the overall architecture, specified requirements, tested everything, and ensured it worked for the business use case.

**Result:** Production-ready system that scales to 50+ clients, all automated, all documented. I now understand GitHub Actions well enough to maintain and extend it, but I didn't have to become an expert to deliver value.

This is "staying in your R lane while extending your reach." The core logic is R code (my expertise). The automation wrapper is GitHub Actions (Claude's expertise).
:::

---

## Client Project Workflow: The Pattern {.smaller}

::: {.incremental}
1. **Understand Requirements** (Human) ‚Üí Define the problem and technical approach
2. **Generate Implementation** (Claude Code) ‚Üí Write the initial code
3. **Review & Course-Correct** (Human) ‚Üí Read every line, check for issues
4. **Iterate Based on Feedback** (Claude Code) ‚Üí Fix problems, refine solution
5. **Final QA & Delivery** (Human) ‚Üí Test thoroughly and ship to client
:::

::: {.fragment}
**Notice the pattern:** Human decisions at the start and end. AI execution in the middle.
:::

::: {.notes}
This is my actual workflow for every client project. Let me walk through what this looks like in practice:

**1. Understand Requirements (Human):** I talk to the client, understand their business problem, and translate that into technical requirements. This is where domain expertise matters‚Äîknowing what questions to ask, understanding their constraints.

**2. Generate Implementation (Claude Code):** I describe what I need to Claude. "Build a Shiny module that handles user authentication." "Create a GitHub Actions workflow for automated testing." Claude generates the initial implementation.

**3. Review & Course-Correct (Human):** This is critical. I read every line of generated code. Does it match my mental model? Are there security issues? Does it follow R best practices? Does it fit the client's existing architecture?

**4. Iterate Based on Feedback (Claude Code):** When I find issues (and I always do), I direct Claude to fix them. "This function should use dplyr instead of base R." "Add error handling for API failures."

**5. Final QA & Delivery (Human):** I test everything thoroughly, write documentation, and deliver to the client. This is where my reputation is on the line‚Äîthe final quality check is always human.

The pattern ensures that strategic decisions and quality control stay with the human, while implementation speed comes from AI assistance.
:::

---

## Managing Your AI Partner {.smaller}

::: columns
::: {.column width="50%"}
**Be Specific with Requirements**

- "Add error handling" ‚Üí "Add tryCatch with informative error messages for API failures"
- "Make it faster" ‚Üí "Use data.table instead of dplyr for this 1M+ row operation"

**Always Review Generated Code**

- Check for security issues (hardcoded credentials, SQL injection risks)
- Verify package dependencies actually exist
- Ensure code follows your team's style guide
:::

::: {.column width="50%"}
**Use Incremental Commits**

- Commit after each successful change
- Makes it easy to roll back when Claude goes off track
- Detailed commit messages help future you understand decisions

**Keep Claude Focused on R**

- Don't let it convince you to rewrite everything in Python
- Stay in your lane‚Äîuse AI to extend reach, not replace your expertise
:::
:::

::: {.notes}
These are hard-won lessons from daily use of Claude Code in client work.

**Be Specific:** Vague instructions get vague results. The more specific you are about what you want, the better Claude's output will be. Think of it like managing a junior developer‚Äîclear requirements lead to better code.

**Always Review:** This cannot be emphasized enough. Claude will confidently generate code that looks right but has subtle bugs. It will hallucinate package functions. It will suggest approaches that work but aren't appropriate for your use case. Your job is to catch these issues.

**Incremental Commits:** This is a game-changer. When you commit frequently, you can easily see what changed and why. When Claude suggests a refactoring that breaks everything, you can quickly revert. Plus, it creates an audit trail of your decision-making.

**Stay in Your Lane:** Claude will sometimes suggest using different languages or frameworks. "This would be easier in Python." Maybe, but if your expertise is R and your client expects R code, stay in R. Use Claude to get better at R, not to escape it.

The goal is to amplify your existing skills, not replace them.
:::

---

## üîë Ruthlessly Solutions-Focused

::: {.fragment}
**AI-assisted development has made me even more ruthlessly solutions-focused for my clients.**
:::

::: {.incremental}
- I'm not thinking about syntax‚ÄîI'm thinking about client outcomes
- I'm not googling package documentation‚ÄîI'm designing system architecture
- I'm not debugging YAML‚ÄîI'm solving business problems
- My mental energy goes to **what matters**: understanding client needs and delivering value
:::

::: {.fragment}
**The technical details still matter‚Äîbut they don't consume my cognitive load anymore.**
:::

::: {.notes}
This is the key insight that ties together everything in Part 2. AI-assisted development hasn't made me lazy or dependent‚Äîit's made me MORE focused on what actually matters to my clients.

**Solutions-Focused, Not Syntax-Focused:** Before AI assistance, a significant portion of my mental energy went to remembering syntax, googling package documentation, debugging configuration files, and wrestling with implementation details. Now, that cognitive load is dramatically reduced. I can focus on the client's actual problem and the best way to solve it.

**From Implementation to Architecture:** My thinking has shifted from "How do I write this function?" to "What's the right architectural approach for this client's needs?" From "What's the correct dplyr syntax?" to "How do we structure this data pipeline for maintainability and scalability?"

**Client Outcomes Over Technical Details:** The technical details still matter‚ÄîI'm not sloppy about code quality or best practices. But they don't dominate my thinking anymore. When I'm in a client meeting, I'm fully present thinking about their business problem, not mentally rehearsing how I'll implement the solution later.

**More Value, Same Time:** This solutions-focus means I deliver more value to clients in the same amount of time. I can iterate faster on approaches, pivot when something isn't working, and explore creative solutions without getting bogged down in implementation details.

**Professional Joy Connection:** This ties back to the "Optimizing for Professional Joy" slide. Being ruthlessly solutions-focused is WHY I find this work satisfying. I'm helping nonprofits and social impact organizations solve real problems, not just writing code. AI assistance lets me operate at the level where I'm most valuable‚Äîstrategic thinking and client partnership, not syntax wrangling.

**The Technical Skills Still Matter:** To be clear, I still need deep R expertise. But that expertise is now deployed strategically‚Äîreviewing Claude's code, making architectural decisions, ensuring quality‚Äîrather than being consumed by basic implementation. This is a elevation of how I use my skills, not a replacement of them.

This is the promise of AI-assisted development for consultants: you become MORE valuable to clients because you can focus your expertise where it matters most.
:::


# Part 3: Building Up Your R Intuition Through Volume

## Learning Through Volume

::: columns
::: {.column width="50%"}
**Traditional Learning:**

- Read docs (30 min)
- Try implementation (1 hour)
- Hit error
- Google/Stack Overflow (20 min)
- Try again (30 min)
- Success? (Maybe)

**Result:** 2.5+ hours for one pattern
:::

::: {.column width="50%"}
**AI-Assisted Learning:**

- Ask Claude (2 min)
- Review code (5 min)
- Test it (5 min)
- Encounter error (immediate)
- Understand WHY it failed
- Iterate (10 min)

**Result:** 22 minutes, 3-4 approaches seen
:::
:::

::: {.fragment}
**Fast iteration builds intuition faster than slow deliberation.**
:::

::: {.notes}
This is the fundamental shift in how I learn R now. It's not about replacing deep learning‚Äîit's about encountering more patterns, more errors, and more solutions in the same amount of time.

**Traditional Learning (2.5+ hours):** You learn one approach deeply, but slowly. You read documentation carefully, implement thoughtfully, debug methodically. It's thorough but time-consuming. You might learn one way to solve a problem.

**AI-Assisted Learning (22 minutes):** You see multiple approaches quickly. Claude generates an implementation, you review it, test it, encounter errors, understand WHY it failed, and iterate. In the same 2.5 hours, you've gone through this cycle 6-7 times, seeing different packages, different patterns, different approaches. You've learned through volume.

**The Learning Advantage:** The key insight is that you're not learning less‚Äîyou're learning MORE through exposure to variety. When Claude makes a mistake with column names (avilist_2025 vs avilist_global), you learn how to inspect package data. When Claude hallucinates a function (make_long), you learn how to verify package capabilities. When Claude's approach doesn't work, you learn to pivot.

**Building Intuition:** Intuition comes from pattern recognition, and pattern recognition requires exposure to lots of patterns. AI-assisted development accelerates this by letting you iterate faster, fail faster, and see more approaches in less time.

**Practical Examples:** This volume approach works for everyday tasks too:
- **Generating fake data:** "Claude, generate realistic university enrollment data" - what would take 20+ minutes of data.frame construction happens in 30 seconds. You learn patterns for realistic data generation.
- **Project scaffolding:** "Claude, create a basic Shiny app structure with modules" - the "getting started" friction is eliminated. You can immediately start on the interesting parts.
- **Documentation:** Claude drafts README files and vignettes that you review and refine.
- **Test data:** Creating edge cases and test scenarios becomes trivial.

This isn't about becoming dependent on AI‚Äîit's about using AI to accelerate the learning process by increasing your exposure to different R patterns and approaches.
:::

---

## When to Use Claude Code vs. Code Yourself {.smaller}

::: columns
::: {.column width="50%"}
**Use Claude Code for:**

::: {.incremental}
- Boilerplate and scaffolding
- Unfamiliar packages/syntax
- Repetitive transformations
- Test data generation
- Documentation writing
- YAML/config files
:::
:::

::: {.column width="50%"}
**Code Yourself for:**

::: {.incremental}
- Business logic
- Client-specific domain knowledge
- Performance-critical sections
- Security-sensitive code
- Final architecture decisions
:::
:::
:::

::: {.fragment}
<div style="text-align: center; margin-top: 20px;">
**The sweet spot:** Use Claude for the "how" while you own the "what" and "why."
</div>
:::

::: {.notes}
This is the decision framework I use every day. Let me explain the reasoning:

**Use Claude Code for:**
- **Boilerplate:** Setting up Shiny modules, package structure, GitHub Actions templates‚Äîthese follow known patterns. Let Claude handle it.
- **Unfamiliar packages:** When I need to use a package I've never used before, Claude can generate example code faster than I can read documentation.
- **Repetitive transformations:** If I'm doing the same data manipulation 20 times with different columns, Claude can generate the variations.
- **Test data:** Creating realistic fake data is tedious. Claude excels at this.
- **Documentation:** Claude can draft README files and function documentation. I review and refine.
- **YAML/config:** These are finicky and tedious. Perfect for AI assistance.

**Code Yourself for:**
- **Business logic:** The core algorithms that make your solution valuable‚Äîthese need human understanding.
- **Client-specific domain knowledge:** Claude doesn't know your client's business. You do.
- **Performance-critical sections:** When milliseconds matter, you need to understand exactly what's happening.
- **Security-sensitive code:** Authentication, authorization, data encryption‚Äîreview these extremely carefully or write them yourself.
- **Architecture decisions:** Should this be a Shiny module or a function? Should we use Supabase or PostgreSQL? These strategic decisions are yours.

The key insight: Claude Code is best for the "how" (implementation details), while you should always own the "what" (requirements) and "why" (strategic decisions).

This framework fits perfectly in Part 3 because it's fundamentally about learning‚Äîunderstanding what tasks help you build R intuition (code yourself) versus what tasks are better delegated (use Claude). When you encounter Claude's mistakes (next slide), this framework helps you decide what to fix yourself versus when to redirect Claude.
:::

---

## Learning from Claude's Real Mistakes {.smaller}

**Claude makes mistakes. This is actually valuable‚Äîhere are real examples from building this presentation:**

::: {.incremental}
**1. The SHINYFA Hallucination**

- Asked Claude to write content about the `{shinyfa}` package
- Claude confidently said it was for "Font Awesome icons in Shiny apps"
- Generated example code: `fa_icon("rocket", fill = "#0051BA")`
- **Reality:** {shinyfa} analyzes Shiny app reactivity patterns (completely different!)
- **Fix:** Provided the actual documentation URL, Claude self-corrected
- **Lesson:** Always verify domain-specific claims, especially for packages

**2. The Column Name Disaster**

- Trying to create bird diversity plots with `{avilistr}` package
- Claude used `avilist_global` dataset (doesn't exist‚Äîit's `avilist_2025`)
- Used lowercase `order_name` column (actual column is `Order`, capitalized)
- Multiple rounds of "Column not found" errors
- **Fix:** Checked the actual package structure: `names(avilist_2025)`
- **Lesson:** When stuck in error loops, inspect the source directly

**3. The Package Function Hunt**

- Wanted a Sankey chart for mental bandwidth visualization
- Claude tried `make_long()` from ggsankey (function doesn't exist)
- Tried `sankeyfy()` (also doesn't exist in that package)
- Multiple package attempts before admitting defeat
- **Fix:** Pivoted to HTML/CSS solution that actually worked
- **Lesson:** Be ready to abandon AI's approach when it's not working
:::

::: {.fragment}
**These mistakes made me a better R developer‚ÄîI had to understand the packages deeply to fix them.**
:::

::: {.notes}
These are three real examples from building this very presentation. Each mistake was a learning opportunity that improved my R skills.

**The SHINYFA Hallucination:** This is documented in the CLAUDE.md file. When I asked Claude to create presentation content about my {shinyfa} package, it completely fabricated what the package does. It assumed from the name that "shinyfa" must be about Font Awesome icons and generated confident, plausible-sounding (but completely wrong) example code. I caught it because I wrote the package‚ÄîI know what it actually does. This taught me to always verify AI-generated content about domain-specific tools, especially in the R ecosystem where package names can be misleading.

**The Column Name Disaster:** This happened while creating the {avilistr} examples. Claude used the wrong dataset name (`avilist_global` instead of `avilist_2025`) and wrong column names (`order_name` instead of `Order`). We went through multiple error cycles before I stopped and actually checked the package structure myself using `names(avilist_2025)`. This forced me to learn how to properly inspect package datasets, check column names, and understand the data structure‚Äîskills I use constantly now.

**The Package Function Hunt:** When creating the mental bandwidth visualization, Claude tried multiple R packages for Sankey charts. It confidently used functions like `make_long()` and `sankeyfy()` that don't actually exist (or don't work as expected). After several failed attempts, I made the call to pivot to an HTML/CSS solution. This taught me that sometimes the "pure R" solution isn't the best solution, and it's okay to use other tools when they're more appropriate.

**The key insight:** Each of these mistakes forced me to develop deeper understanding. I couldn't just accept Claude's output‚ÄîI had to understand the packages, data structures, and available functions well enough to correct the errors. This is exactly the kind of learning that builds intuition and makes you a better developer. You're not becoming dependent on AI; you're accelerating your learning by encountering (and fixing) more problems faster than traditional development would expose you to.
:::

---

## The Failing Fast Advantage

```{r}
#| echo: true
#| eval: false

# Traditional development:
attempts <- 1
learning <- "slow and careful"

# AI-assisted development:
attempts <- 10
learning <- "rapid pattern recognition"

# You encounter and solve more problems in less time
# Each failure teaches you something about:
# - What works in R
# - What's idiomatic
# - What's maintainable
# - What's efficient
```

---

## The 80% Problem: AI Limitations {.smaller}

**Not everything AI generates is production-ready.**

::: columns
::: {.column width="50%"}
**Where AI Excels:**

- Boilerplate code
- Standard patterns
- Initial structure
- Quick prototypes
- Documentation drafts
:::

::: {.column width="50%"}
**Where AI Falls Short:**

- Data cleaning scripts (‚âà80% okay)
- Edge case handling
- Domain-specific logic
- Performance optimization
- Security considerations
:::
:::

<br>

::: {.fragment}
**The term:** "AI Slop" - code that *technically works* but isn't quite right.
:::

---

## Over-Abstraction Warning

```{r}
#| echo: true
#| eval: false

# Claude's suggestion (over-abstracted):
create_advanced_pipeline <- function(data, config, transformations, validators,
                                      error_handlers, logging_strategy, ...) {
  # 200 lines of abstraction
}

# What I actually need (maintainable):
clean_data <- function(data) {
  data |>
    filter(!is.na(key_column)) |>
    mutate(date = as.Date(date))
}

# Keep it simple. Keep it readable. Keep it maintainable.
```

# Part 4: Human In/On the Loop

---

## Establishing Your AI Values

Before integrating AI into your workflow, ask yourself:

::: {.incremental}
1. **What code can I maintain 6 months from now?**
2. **Where do I need to maintain expertise?**
3. **What represents my core value proposition?**
4. **What should I always understand deeply?**
:::

::: {.fragment}
**These become your guardrails.**
:::

---

## Defining the Relationship

**Claude is not your boss. Claude is your colleague.**

::: columns
::: {.column width="50%"}
**Claude as Colleague:**

- Suggests approaches
- Generates initial drafts
- Handles boilerplate
- Explores alternatives
- Speeds up research
:::

::: {.column width="50%"}
**You as Leader:**

- Make architectural decisions
- Review and refine code
- Ensure maintainability
- Apply domain expertise
- Own the final product
:::
:::

---

## The Dumpster Fire Prevention Rule

**If you can't explain the code, you don't own it.**

```{r}
#| echo: true
#| eval: false

# Bad: AI-generated code you don't understand
result <- complex_ai_function(data, params = list(
  algorithm = "advanced_ml_technique",
  hyperparameters = list(alpha = 0.05, beta = 0.9, gamma = 2.5),
  cross_validation = TRUE,
  ensemble_method = "stacking"
))

# Good: Code you understand and can maintain
result <- data |>
  filter(status == "active") |>
  group_by(category) |>
  summarize(total = sum(value))

# If you can't debug it, don't ship it.
```

---

## Example 4: Quarto Over JavaScript {.smaller}

**The Scenario:**

- Client wants an interactive dashboard
- AI suggests a JavaScript framework (React, Vue, etc.)
- Impressive demo, cutting-edge tech

**The Problem:**

- I'm an R developer, not a JavaScript expert
- Client needs updates and maintenance
- In 6 months, can I confidently modify this code?

---

## Staying in Your Lane

```{r}
#| echo: true
#| eval: false

# Instead of AI-generated JavaScript:
# ‚ùå Complex build process
# ‚ùå Node dependencies
# ‚ùå Framework-specific patterns I don't deeply understand

# I chose Quarto:
# ‚úÖ Markdown-based (familiar)
# ‚úÖ R code chunks (my expertise)
# ‚úÖ Easy to maintain
# ‚úÖ Client can understand the structure

library(ggplot2)
library(dplyr)

# This is my wheelhouse
# I can modify this at 2am if needed
# The client can read this
```

---

## When to Override AI

You should override or ignore AI suggestions when:

1. The solution is over-engineered for your needs
2. It uses technologies outside your maintenance capacity
3. It introduces dependencies you don't want to manage
4. You can't explain it to your client
5. It feels like "magic" instead of logic

**Your expertise is your compass.**

---

## Your AI Values Exercise

Before your next AI-assisted project, write down:

1. **What I will always do myself:**
2. **What AI can help me with:**
3. **What I need to understand deeply:**
4. **What I'm comfortable delegating:**

**This clarity prevents the dumpster fire.**


# Conclusion

## The Four Pillars of AI-assisted development

::: columns
::: {.column width="50%"}
**1. Mental Bandwidth**

- 10-20% time back
- Strategic focus
- Creative projects

**2. Bigger Problems**

- Say yes to growth
- Expand service offerings
- Comprehensive solutions
:::

::: {.column width="50%"}
**3. Accelerated Learning**

- High-volume iteration
- Pattern recognition
- Fail fast, learn faster

**4. Human Leadership**

- Establish AI values
- Maintain expertise
- Own the final product
:::
:::

---

## Hand on the Wheel

**Key Principle:** AI accelerates; you steer.

::: {.incremental}
- **Let AI generate** the boilerplate, the repetitive code, the initial structure
- **You maintain** the architecture, the business logic, the critical decisions
- **Review everything** like you're mentoring an intern
- **Refactor freely** to match your style and standards
- **Test thoroughly** because AI doesn't understand your edge cases
:::

---

## The Core Philosophy

**AI doesn't replace expertise.**

**It amplifies it.**

<br>

::: {.incremental}
- You remain the architect
- You maintain the standards
- You own the relationships
- You deliver the value
:::

---

## Final Thoughts {.center}

> "When AI frees up your mental bandwidth,
> you don't get lazy‚Äîyou get strategic."

<br>

**Stay in your lane.**

**Keep your hand on the wheel.**

**Build with confidence.**

---

## Thank You {.center}

![](images/horizontal-logo.png){width=60% fig-align="center"}

**Questions?**

<br>

Contact: [jasmine@dalyanalytics.com]

GitHub: [@jasdumas]

Website: [dalyanalytics.com]

::: {.notes}
Thank you all for your time. I'm happy to take questions about AI-assisted development, R workflows, or anything else we've covered today.
:::

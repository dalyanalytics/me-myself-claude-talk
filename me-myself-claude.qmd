---
title: "Me, Myself & Claude"
subtitle: "How I Leverage AI-Assisted Development to Scale My Solo R-based Data Science Consultancy"
author: "Jasmine Daly<br>Principal Consultant & Founder<br>Daly Analytics"
date: "Wednesday, November 12, 2025"
format:
  revealjs:
    theme: [simple, theme/daly-analytics.scss]
    transition: slide
    slide-number: true
    chalkboard: true
    preview-links: auto
    code-line-numbers: false
    highlight-style: github
    logo: images/sunset.png
---

## Introduction {.center}

**AI-Assisted Development in R**

A journey of staying in your lane while scaling your impact!

::: {.notes}
Hello everyone! Today I want to share my experience integrating AI into my R development workflow - not as a replacement for expertise, but as a strategic force multiplier.
:::

---

## Who Am I? {.smaller}

- R Developer & Data Scientist since 2014
- Maintainer of {shinyLP}, {ttbbeer}, {avilistr}^, {shinyfa}^
- Running a *mostly* solo consultancy focused on delivering solutions with data science, analytics & AI 
- Building Shiny applications, interactive dashboards, and data automation pipelines


::: {.notes}
To level-set everyone and provide some context: I'm a mom of 2 young kids with limited time resources. I'm also an active Volunteer in my local community.

I'm managing both the technical (writing code) and business sides (doing discovery/sales calls) of my practice. I just recently onboarded a subcontractor this Summer that provides adhoc shiny development support, which has been wonderful in delegating tasks to them. 
:::

---

## ðŸ”‘ Moving Beyond 'Vibe Coding' {.smaller}

::: columns
::: {.column width="60%"}
**Words matter. Let's reframe the conversation.**

::: {.incremental}
- **"Vibe Coding"** â†’ Implies reckless, hope-based development
- **"Vibe Engineering"** â†’ Intentional, accountable AI-assisted development
- **"I'm adding a new (agentic) tool to my tool box"** â†’ Honest acknowledgment of exploration of this phase of hypergrowth and learning
:::
:::

::: {.column width="40%"}
![](images/vibes.jpeg){width=100%}
:::
:::

::: {.notes}
Credit to Christopher Fitkin's LinkedIn post on "vibe engineering" which really resonated with me.

One of the key takeaways of this entire talk is to reframe our language around how we talk about AI-assisted coding. "Vibe Coding" - while often funny - really diminishes our impact and the capacity for others to understand our lived experience as software developers.

It also does a disservice to our community when it comes to advocating for democratizing our field for diverse participants while also trying to emphasize the real complexity around ethics, governance, and professional responsibility.

The distinction Fitkin makes is critical: "vibe coding" suggests careless dependency where you hope AI outputs work. "Vibe engineering" means experienced developers intentionally leveraging AI tools while maintaining full accountability.

This isn't about replacing human expertise - it's about experienced engineers guiding AI tool adoption as an enhancement to craft, not a substitute for professional judgment.

**The Reality:** We're in an **exploratory phase**. There are no settled best practices yet. Making mistakes is part of professional growth. But you remain **fully accountable** for the outcome.

tl;dr: it's hard to say things are easy, give people the confidence and tools and then back track and say 'well that's not serious data science" so everything you 'vibe coded' shouldnt be used.
:::

# Part 1: Strategic Thinking Unlocked for Greater Community Contributions

## The Mental Bandwidth Shift {.smaller}

<div style="display: flex; justify-content: center; align-items: center; gap: 40px; padding: 20px 10px; max-width: 100%; margin: 0 auto;">

<div style="text-align: center; flex: 1; max-width: 280px;">
<h3 style="font-size: 1.6em; margin-bottom: 15px; color: #404041; font-weight: bold;">Before AI</h3>

<div style="background: #6A94C9; height: 340px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1.2em; font-weight: bold; color: white; line-height: 1.3;">Client Dev</div>
<div style="font-size: 2em; font-weight: bold; color: white; margin-top: 5px;">85%</div>
</div>

<div style="background: #D68A93; height: 60px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); overflow: visible;">
<div style="font-size: 0.95em; font-weight: bold; color: white; line-height: 1.2;">Biz Dev 15%</div>
</div>
</div>

<div style="text-align: center; flex: 0 0 auto;">
<div style="font-size: 4em; color: #F9B397; font-weight: bold; line-height: 1;">â†’</div>
<div style="font-size: 1em; color: #404041; font-weight: bold; margin-top: 5px; line-height: 1.2;">AI Unlocks<br>15%</div>
</div>

<div style="text-align: center; flex: 1; max-width: 280px;">
<h3 style="font-size: 1.6em; margin-bottom: 15px; color: #404041; font-weight: bold;">With AI</h3>

<div style="background: #6A94C9; height: 280px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1.2em; font-weight: bold; color: white; line-height: 1.3;">Client Dev</div>
<div style="font-size: 2em; font-weight: bold; color: white; margin-top: 5px;">70%</div>
</div>

<div style="background: #D68A93; height: 100px; display: flex; flex-direction: column; justify-content: center; margin-bottom: 8px; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Biz Dev</div>
<div style="font-size: 1.6em; font-weight: bold; color: white; margin-top: 3px;">25%</div>
</div>

<div style="background: #AD92B1; min-height: 40px; height: 40px; display: flex; flex-direction: column; justify-content: center; border-radius: 6px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); padding: 5px 10px;">
<div style="font-size: 0.85em; font-weight: bold; color: white; line-height: 1.1;">Community 5%</div>
</div>
</div>

</div>

::: {.notes}
This visualization shows the most fundamental shift that AI-assisted development has created for me as a solo consultant.

**Before AI:** 85% of my mental energy and time went to client development work. That's writing code, debugging, implementing features, wrestling with syntax. Only 15% went to business developmentâ€”proposals, networking, marketing, financial planning. There was no room for anything else.

**The AI Impact:** AI assistance freed up 15% of my cognitive capacity. Not by making me work less, but by making the technical work less mentally taxing. I'm still doing client dev, but it drops from 85% to 70% because tasks that used to take hours (debugging YAML, googling package syntax, scaffolding boilerplate) now take minutes.

**The Reallocation:** That 15% didn't disappearâ€”it got redistributed:
- **Business Development grew from 15% to 25%** - Now I can actually do proper business operations: automated systems, financial planning, strategic thinking about where the consultancy is going.
- **Community Contribution became possible at 5%** - Before AI, open source contributions felt like a luxury I couldn't afford. Now I have capacity for packages like {shinyfa} and {avilistr}, conference talks like this one, and community engagement.

**The Key Insight:** This isn't about working more hours. It's about cognitive load. When AI handles the syntax details, documentation lookups, and boilerplate generation, my brain has room for strategic thinking, creative problem-solving, and community engagement. That's the mental bandwidth shift.

This slide sets up everything that follows in the talkâ€”all four parts are enabled by this fundamental reallocation of cognitive capacity.
:::

---


## What Mental Bandwidth Buys You

::: {.incremental}
- **Better Biz Ops:** Improving my systems to be automated and Standardized
- **Financial Clarity:** Time to understand cash flow, pricing strategy, and profitability
- **Relationship Building:** Networking, content creation, community engagement
- **Creative Space:** Room to think about what *could* be built, not just what *must* be built
:::

::: {.notes}
The mental bandwidth shift from 85% client dev to 70% client dev freed up 15% of my cognitive capacity. That 15% doesn't sound like much, but it's transformational.

**Better Biz Ops:** I now have time to build automated systems and standardized processes. Proposals, contracts, invoicing - things that used to be rushed now have proper templates and workflows.

**Financial Clarity:** Understanding cash flow, pricing strategy, and profitability isn't a "someday" task anymore. I can make strategic financial decisions instead of reactive ones.

**Relationship Building:** Networking isn't just attending events - it's consistent content creation, community engagement, and showing up in ways that build long-term relationships.

**Creative Space:** This is the big one. I now have room to think about what *could* be built, not just what *must* be built. That's where packages like {shinyfa} come from - tapping into real and persistent problems and creative exploration that serves the community.

Before AI: I was always feeling behind on the business side, constantly in reactive mode.

After AI: More strategic, more sustainable, and more creative. I'm building a business, not just executing projects.
:::

---

## The {shinyfa} Package <img src="images/shinyfa.png" width="80" style="vertical-align: middle; margin-left: 10px;"> {.smaller}

::: columns
::: {.column width="45%"}

<div style="display: flex; flex-direction: column; gap: 15px; margin-top: 20px;">

<div style="background: #6A94C9; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Client Problem</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Months to navigate large Shiny app</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">â†“</div>

<div style="background: #AD92B1; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Quick Script</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Analyze file structure</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">â†“</div>

<div style="background: #D68A93; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">CRAN Package</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Community tool</div>
</div>

</div>

::: {.fragment}
<div style="text-align: center; margin-top: 15px; font-size: 0.9em;">
**Before AI:** "Nice someday project."

**With AI:** Built and released in weeks.
</div>
:::
:::

::: {.column width="55%"}
**Output:**

| file_name | type | name |
|-----------|------|------|
| ui.R | input | selectInput |
| ui.R | output | plotOutput |
| server.R | reactive | filtered_data |
| server.R | render | renderPlot |
| modules/map.R | input | sliderInput |
| modules/map.R | render | renderLeaflet |

::: {.fragment}
Catalog of render functions, reactive functions, inputs, and file relationships across your entire Shiny app.
:::
:::
:::

::: {.notes}
This is a perfect example of how AI freed up mental bandwidth for creative work.

**The Flowchart (Left):**
- **Client Problem:** I was contracted to work on a large, complex Shiny app for a conservation nonprofit. It took me MONTHS to get comfortable in their repo - understanding which files did what, how the reactive dependencies flowed, where inputs and outputs were defined.
- **Quick Script:** About halfway through, I realized: "I'm a Shiny developer. There has to be a better way to systematically analyze app structure." So I wrote a one-off script to catalog render functions, reactive functions, inputs, and file relationships.
- **CRAN Package:** That script was so useful that I kept refining it. Then I thought - "Other developers face this same problem." With Claude's help, I generalized those functions, added documentation, built tests, and packaged it up as {shinyfa}.

**The Output Table (Right):** The result is a dataframe that gives you a complete map of your app's structure. Each row represents a reactive element: inputs, outputs, reactive expressions, and render functions. You can see which file they're in, what type they are, their name, and how they connect.

**Why This Matters:** For that conservation nonprofit project, this would have been transformational during onboarding. Instead of manually searching through dozens of files asking "where is the species input used?", you get a structured dataset you can query: `file_analysis %>% filter(input_id == "species")` and instantly see everywhere it's referenced.

**The Power:** You can answer questions like:
- "Show me all render functions in the modules folder"
- "Which files have reactive expressions?"
- "What outputs don't have corresponding render functions?" (potential bugs!)
- "Map the flow from this input to its output"

**The Timeline:** The entire process from "useful script" to "published package" took weeks, not months. Without AI assistance, this would have stayed as a one-off script on my hard drive, or been a "someday" project I never got to.

**The Impact:** This is what mental bandwidth buys you: the ability to take a client problem, generalize it, and contribute a tool back to the community - all without sacrificing your business. {shinyfa} solves a problem I experienced repeatedly - onboarding developers to complex Shiny apps. It would have saved me weeks during that client engagement.
:::

---

## The {avilistr} Package <img src="images/avilistr.png" width="80" style="vertical-align: middle; margin-left: 10px;"> {.smaller}

::: columns
::: {.column width="45%"}
<div style="display: flex; flex-direction: column; gap: 15px; margin-top: 20px;">

<div style="background: #AD92B1; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">New Hobby</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">Started birding, found taxonomy in Excel</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">â†“</div>

<div style="background: #6A94C9; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">Wrap Excel</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">11k+ species, Cornell Lab codes</div>
</div>

<div style="text-align: center; font-size: 2.5em; color: #F9B397; font-weight: bold; line-height: 0.5;">â†“</div>

<div style="background: #D68A93; padding: 12px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 1em; font-weight: bold; color: white; line-height: 1.2;">CRAN Package</div>
<div style="font-size: 0.85em; color: white; margin-top: 5px;">In a weekend</div>
</div>

</div>

::: {.fragment}
<div style="text-align: center; margin-top: 20px; font-size: 0.9em;">
**Before AI:** "Nice to have, not crucial."

**With AI:** Published with docs in a weekend.
</div>
:::
:::

::: {.column width="55%"}
**Output:**
```{r}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 5

library(ggplot2)
library(dplyr)
library(avilistr)

data(avilist_2025)

order_diversity <- avilist_2025 %>%
  filter(Taxon_rank == "species") %>%
  count(Order, sort = TRUE) %>%
  filter(n > 100)

ggplot(order_diversity, aes(x = reorder(Order, n), y = n)) +
  geom_col(fill = "#6A94C9") +
  coord_flip() +
  labs(title = "Bird Diversity by Order",
       subtitle = "Over 100 species",
       x = NULL, y = "Number of Species") +
  theme_minimal(base_size = 11)
```

::: {.fragment}
**Passeriformes:** 6,700+ species (over half of all birds!)
:::
:::
:::

::: {.notes}
**The Personal Story:** I started birding in 2025 - a new hobby outside of tech. I discovered the AviList Global Avian Checklist (unified global bird taxonomy) in Excel format. For R users working with bird data - especially integrating with eBird through {rebird} - having this taxonomy in R makes workflows cleaner.

**The Flowchart (Left):**
- **New Hobby:** Started birding, discovered the Excel taxonomy
- **Wrap Excel:** Converted 11,131 species + Cornell Lab codes to R
- **CRAN Package:** Published in less than a week with comprehensive docs

**The Visualization (Right):** Shows bird diversity by taxonomic order. Passeriformes (perching birds/songbirds) dominates with 6,700+ species - over 60% of all bird species. This kind of exploratory analysis is what R birders want to do.

**The Technical Reality:** Total honesty - this wasn't groundbreaking. I took a published Excel sheet and wrapped it into an R package. The Excel conversion was straightforward, not a heavy lift.

**Where AI Made the Difference:** The real work was documentation. The getting-started vignette shows practical workflows: exploring species, finding specific groups (194 thrush species), comparing taxonomies, connecting to eBird observations. Claude helped structure vignettes and write clear examples.

**The Timeline:** With AI, I focused on "what examples help birders?" vs. getting bogged down in documentation tedium. From idea to CRAN with comprehensive docs: less than a week.

**The Bigger Message:** Lowering the barrier to contribution. You don't need technical complexity to add value. Sometimes it's "take this useful thing in the wrong format and make it accessible" - and with AI, doing that WELL (with good docs!) becomes feasible in days, not months.

Finding common ground in open source: birding + R + accessibility = a contribution I'm genuinely proud of.
:::

---

## ðŸ”‘ The Creative Multiplier

AI assistance doesn't just save time on what you were already doing.

**It unlocks what you weren't doing at all:**

- Open source contributions (like shinyfa and avilistr)
- Writing better tests and documentation
- Building developer tools that solve real problems
- Package development with proper structure
- Community engagement and knowledge sharing

::: {.notes}
*Side note: ChatGPT is great for hex sticker design and branding ideas!*
:::

::: {.notes}
{ttbbeer} my first package was released July 2016 and 
{shinyLP} my second package was first released on September 2016. The next CRAN package i released was {avilistr} in June 2025. That's 8 years 9 months (September 16, 2016â€‰â€“â€‰June 17, 2025)
:::


# Part 2: Saying Yes to Bigger & Funner Problems

## Optimizing for Professional Joy {.smaller}

![](images/professional-joy.png){width=120%; fig-align="center"}

::: {.notes}
This is the core philosophy that drives everything in Part 2. I'm running a solo consultancy, and I could optimize for different thingsâ€”maximum revenue, maximum number of clients, or rapid business growth. But that's not what I'm after.

**The Venn Diagram:** Professional joy sits at the intersection of four overlapping areas:

**Client Work (Blue):** Values-aligned clientsâ€”nonprofits, social impact organizations, NGOs. These are organizations doing important work in the world, often with limited resources. High personal interaction and deep relationships, not transactional projects. Quality over quantityâ€”I'd rather work with 5 clients I'm deeply invested in than 20 clients where I'm just checking boxes.

**Technical Growth (Purple):** Challenging problems that expand my R expertise. Working on problems that challenge me technicallyâ€”learning new packages, exploring new approaches, building expertise in data engineering, automation, and infrastructure. This keeps the work interesting and valuable.

**Community (Pink):** Professional development through community engagementâ€”speaking at conferences like this one, contributing open source packages ({shinyfa}, {avilistr}), participating in the R community, continuous learning. These activities don't directly generate revenue, but they're essential to professional satisfaction and long-term growth.

**Life Balance (Orange):** Not sacrificing home life for business growth. I'm a solo consultant, not a startup founder trying to build a unicorn. I have a life outside of work that mattersâ€”family, hobbies, health. Sustainable consulting means not burning out.

**Professional Joy (Center):** Where all four overlap. This is the sweet spot where I'm doing meaningful client work, growing technically, contributing to community, and maintaining life balance.

**The AI Advantage:** Here's where AI becomes transformative. It doesn't just save me timeâ€”it gives me the capacity to be *selective*. I can say YES to the projects that bring professional joy and NO to the ones that don't, because AI assistance means I'm not constantly capacity-constrained. I can take on challenging technical problems without sacrificing quality or work-life balance.

This philosophy sets up everything that follows in Part 2. The technical skills and workflows I'm about to share aren't about doing more workâ€”they're about doing the *right* work, with the *right* clients, in a way that's sustainable and joyful.
:::

---

## The Old Filter

Before AI-assisted development, my filter for new projects was:

> "Can I build this in a reasonable timeframe with my current skillset given my existing client workload?"

::: {.notes}
**This often meant saying NO to:**

- Projects requiring unfamiliar R packages 
- Learning new techniques to support the project
- Interesting client opportunities
:::
---

## The New Filter

With AI-assisted development, my new filter has become:

> "I can certainly build it! 
How can I thoughtfully spend time deeply understanding the desired outcome & client constraints?"

::: {.notes}
**Now I can say YES to:**

- Pipeline development and automation
- Data engineering workflows
- Complex hosting solutions
- Technologies outside my comfort zone but within my skillset
:::
---

## Claude Code as My Coding Partner {.smaller}

::: columns
::: {.column width="50%"}
**The Mental Model**

::: {.incremental}
- **I'm the manager**: Setting direction, making architectural decisions
- **Claude is my senior developer partner**: Implementing solutions, handling boilerplate
- **Human in/on the loop**: Active technical leadership stays with me
:::
:::

::: {.column width="50%"}
**Tips & Tricks for Managing the Partnership**

::: {.incremental}
- Be specific with requirements
- Always review generated code
- Use incremental commits
- Feed documentation links
- Ask for multiple options
- Run Claude in parallel across related repos
:::
:::
:::

::: {.fragment}
With Claude's help I **amplify my capacity** to take on bigger, more interesting problems.
:::

::: {.notes}
This is the critical mental model shift and the practical techniques I use daily in client work.

**The Mental Model:**

**You are the manager:** You understand client requirements, make architectural decisions, choose the technology stack, and own the final deliverable.

**Claude is your senior developer partner:** It handles implementation details, writes boilerplate, suggests approaches, and speeds up the coding process.

**Human in/on the loop:** You review everything, test rigorously, and course-correct when Claude goes off track. Your technical judgment ensures quality.

**My Daily Tips & Tricks:**

**Be Specific with Requirements:** Vague instructions get vague results. "Add error handling" â†’ "Add tryCatch with informative error messages for API failures." "Make it faster" â†’ "Use data.table instead of dplyr for this 1M+ row operation."

**Always Review Generated Code:** Check for security issues (hardcoded credentials, SQL injection risks), verify package dependencies actually exist, ensure code follows your style guide. Claude will confidently generate code that looks right but has subtle bugs or hallucinates package functions.

**Use Incremental Commits:** Commit after each successful change. Makes it easy to roll back when Claude goes off track. Detailed commit messages help future you understand decisions.

**Leverage Context & Tools:** I use MCP tools (like mcptools for R session integration) to give Claude better context about my running R environment. This dramatically improves code suggestions.

**Feed Documentation Links:** When working with specific packages or APIs, I provide Claude with direct links to documentation. "Read this shinyfa documentation: https://dalyanalytics.github.io/shinyfa/" This prevents hallucinations and ensures accurate code generation.

**Feed Other AI Prompts:** Sometimes I brainstorm with Claude first, take those ideas to another AI for a different perspective, then bring both back to Claude for synthesis. Cross-pollinating ideas leads to better solutions.

**Ask for Multiple Options:** Instead of accepting Claude's first suggestion, I ask "Give me 3 different approaches to this problem." Then I often go with a hybrid solution combining the best parts of each.

**Run Claude in Parallel:** For complex projects like my GitHub Actions data orchestration system, I have multiple Positron IDE windows openâ€”one for the orchestration repo, one for the dashboard template, one for a client dashboard. I run Claude in parallel across these related repos, which lets me work on the full system architecture simultaneously while maintaining context in each repo.

**Stay in Your Lane:** Don't let Claude convince you to rewrite everything in Python. Use AI to extend your R expertise, not replace it.

This model lets you say YES to bigger projects while maintaining the quality and technical ownership that makes you valuable to clients. Claude is a tool and partnerâ€”you're still the expert leading the work.
:::

---

## Client Example: Using GitHub Actions For Data Orchestration {.smaller}

<div style="display: flex; flex-direction: column; gap: 12px; margin: 20px auto; max-width: 90%;">

<div style="background: #6A94C9; padding: 10px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 0.9em; font-weight: bold; color: white;">Data Orchestration Repo</div>
<div style="font-size: 0.75em; color: white; margin-top: 3px;">GitHub Actions (API, webhooks, Railway)</div>
</div>

<div style="text-align: center; font-size: 2em; color: #F9B397; font-weight: bold; line-height: 0.3;">â†“</div>

<div style="background: #AD92B1; padding: 10px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 0.9em; font-weight: bold; color: white;">Load Data in Supabase</div>
<div style="font-size: 0.75em; color: white; margin-top: 3px;">RLS rules per client_id for data isolation</div>
</div>

<div style="text-align: center; font-size: 2em; color: #F9B397; font-weight: bold; line-height: 0.3;">â†“</div>

<div style="background: #D68A93; padding: 10px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 0.9em; font-weight: bold; color: white;">Client Dashboards (Quarto)</div>
<div style="font-size: 0.75em; color: white; margin-top: 3px;">50+ dashboards on Netlify, each pulls only their data</div>
</div>

<div style="text-align: center; font-size: 2em; color: #F9B397; font-weight: bold; line-height: 0.3;">â†“</div>

<div style="background: #F9B397; padding: 10px 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
<div style="font-size: 0.9em; font-weight: bold; color: white;">Template System</div>
<div style="font-size: 0.75em; color: white; margin-top: 3px;">Shared components, feature toggles, GH Action PRs for updates</div>
</div>

</div>

::: {.fragment}
**Right-sized enterprise-grade infrastructure built in a few weeks with Claude Code's help.**
:::

::: {.notes}
This is a real example from my client work. They needed an enterprise-grade (but right-sized) data automation system to manage 50+ client dashboards, each with different refresh schedules and features.

**The Client Challenge (Left):**
- **50+ clients:** Each with their own dashboard
- **Different schedules:** Daily, weekly, monthly, quarterly refreshes
- **Complex infrastructure:** Scheduled pipelines, testing workflows, deployment triggers
- **Cross-repo coordination:** Repository dispatch events to trigger builds in separate repos

**The YAML (Right):** This is actual code from the system. Look at what's happening:
- **Scheduled trigger:** `cron: '0 6 * * *'` runs daily at 6 AM UTC, processes all clients based on their individual refresh schedules
- **Manual trigger:** `workflow_dispatch` allows testing on demand
- **R integration:** Sets up R environment, installs packages, runs the orchestrator script
- **Secrets management:** Properly uses GitHub secrets for cross-repo operations and database access

**The Key Insight:** I didn't need to memorize GitHub Actions syntax. I needed to understand the architectureâ€”what needs to happen, when, and why. Claude Code handled translating that understanding into correct YAML.

**My Approach:** I understood the architecture (what needed to happen and when), but I didn't want to spend weeks becoming a GitHub Actions expert.

**Claude's Role:** Generated the YAML workflows, helped set up the orchestrator pattern, created the manual testing workflows, and built the configuration-driven scheduling system.

**My Role:** Designed the overall architecture, specified requirements, tested everything, and ensured it worked for the business use case.

**Result:** Production-ready system that scales to 50+ clients, all automated, all documented. I now understand GitHub Actions well enough to maintain and extend it, but I didn't have to become an expert to deliver value.

This is "staying in your R lane while extending your reach." The core logic is R code (my expertise). The automation wrapper is GitHub Actions (Claude's expertise).
:::

---

## Client Project Workflow {.smaller}

::: {.incremental}
1. **Understand Requirements** (Human) â†’ Define the problem and technical approach
2. **Generate Implementation** (Claude Code) â†’ Write the initial code
3. **Review & Course-Correct** (Human) â†’ Read every line, check for issues
4. **Iterate Based on Feedback** (Claude Code) â†’ Fix problems, refine solution
5. **Final QA & Delivery** (Human) â†’ Test thoroughly and ship to client
:::

::: {.fragment}
**Notice the pattern:** Human decisions at the start and end. AI execution in the middle.
:::

::: {.notes}
This is my actual workflow for every client project. Let me walk through what this looks like in practice:

**1. Understand Requirements (Human):** I talk to the client, understand their business problem, and translate that into technical requirements. This is where domain expertise mattersâ€”knowing what questions to ask, understanding their constraints.

**2. Generate Implementation (Claude Code):** I describe what I need to Claude. "Build a Shiny module that handles user authentication." "Create a GitHub Actions workflow for automated testing." Claude generates the initial implementation.

**3. Review & Course-Correct (Human):** This is critical. I read every line of generated code. Does it match my mental model? Are there security issues? Does it follow R best practices? Does it fit the client's existing architecture?

**4. Iterate Based on Feedback (Claude Code):** When I find issues (and I always do), I direct Claude to fix them. "This function should use dplyr instead of base R." "Add error handling for API failures."

**5. Final QA & Delivery (Human):** I test everything thoroughly, write documentation, and deliver to the client. This is where my reputation is on the lineâ€”the final quality check is always human.

The pattern ensures that strategic decisions and quality control stay with the human, while implementation speed comes from AI assistance.
:::

---

## ðŸ”‘ Ruthlessly Solutions-Focused

::: {.fragment}
**AI-assisted development has made me even more ruthlessly solutions-focused for my clients.**
:::

::: {.incremental}
- I'm not thinking about syntaxâ€”I'm thinking about client outcomes
- I'm not googling package documentationâ€”I'm designing system architecture
- I'm not debugging YAMLâ€”I'm solving business problems
- My mental energy goes to **what matters**: understanding client needs and delivering value
:::

::: {.fragment}
**The technical details still matterâ€”but they don't consume my cognitive load anymore.**
:::

::: {.notes}
This is the key insight that ties together everything in Part 2. AI-assisted development hasn't made me lazy or dependentâ€”it's made me MORE focused on what actually matters to my clients.

**Solutions-Focused, Not Syntax-Focused:** Before AI assistance, a significant portion of my mental energy went to remembering syntax, googling package documentation, debugging configuration files, and wrestling with implementation details. Now, that cognitive load is dramatically reduced. I can focus on the client's actual problem and the best way to solve it.

**From Implementation to Architecture:** My thinking has shifted from "How do I write this function?" to "What's the right architectural approach for this client's needs?" From "What's the correct dplyr syntax?" to "How do we structure this data pipeline for maintainability and scalability?"

**Client Outcomes Over Technical Details:** The technical details still matterâ€”I'm not sloppy about code quality or best practices. But they don't dominate my thinking anymore. When I'm in a client meeting, I'm fully present thinking about their business problem, not mentally rehearsing how I'll implement the solution later.

**More Value, Same Time:** This solutions-focus means I deliver more value to clients in the same amount of time. I can iterate faster on approaches, pivot when something isn't working, and explore creative solutions without getting bogged down in implementation details.

**Professional Joy Connection:** This ties back to the "Optimizing for Professional Joy" slide. Being ruthlessly solutions-focused is WHY I find this work satisfying. I'm helping nonprofits and social impact organizations solve real problems, not just writing code. AI assistance lets me operate at the level where I'm most valuableâ€”strategic thinking and client partnership, not syntax wrangling.

**The Technical Skills Still Matter:** To be clear, I still need deep R expertise. But that expertise is now deployed strategicallyâ€”reviewing Claude's code, making architectural decisions, ensuring qualityâ€”rather than being consumed by basic implementation. This is a elevation of how I use my skills, not a replacement of them.

This is the promise of AI-assisted development for consultants: you become MORE valuable to clients because you can focus your expertise where it matters most.
:::


# Part 3: Building Up Your R Intuition Through Volume

## Learning Through Volume

::: columns
::: {.column width="50%"}
**Traditional Learning:**

- Read docs (30 min)
- Try implementation (1 hour)
- Hit error
- Google/Stack Overflow (20 min)
- Try again (30 min)
- Success? (Maybe)

**Result:** 2.5+ hours for one pattern
:::

::: {.column width="50%"}
**AI-Assisted Learning:**

- Ask Claude (2 min)
- Review code (5 min)
- Test it (5 min)
- Encounter error (immediate)
- Understand WHY it failed
- Iterate (10 min)

**Result:** 22 minutes, 3-4 approaches seen
:::
:::

::: {.fragment}
**Fast iteration builds intuition faster than slow deliberation.**
:::

::: {.notes}
This is the fundamental shift in how I learn R now. It's not about replacing deep learningâ€”it's about encountering more patterns, more errors, and more solutions in the same amount of time.

**Traditional Learning (2.5+ hours):** You learn one approach deeply, but slowly. You read documentation carefully, implement thoughtfully, debug methodically. It's thorough but time-consuming. You might learn one way to solve a problem.

**AI-Assisted Learning (22 minutes):** You see multiple approaches quickly. Claude generates an implementation, you review it, test it, encounter errors, understand WHY it failed, and iterate. In the same 2.5 hours, you've gone through this cycle 6-7 times, seeing different packages, different patterns, different approaches. You've learned through volume.

**The Learning Advantage:** The key insight is that you're not learning lessâ€”you're learning MORE through exposure to variety. When Claude makes a mistake with column names (avilist_2025 vs avilist_global), you learn how to inspect package data. When Claude hallucinates a function (make_long), you learn how to verify package capabilities. When Claude's approach doesn't work, you learn to pivot.

**Building Intuition:** Intuition comes from pattern recognition, and pattern recognition requires exposure to lots of patterns. AI-assisted development accelerates this by letting you iterate faster, fail faster, and see more approaches in less time.

**Practical Examples:** This volume approach works for everyday tasks too:
- **Generating fake data:** "Claude, generate realistic university enrollment data" - what would take 20+ minutes of data.frame construction happens in 30 seconds. You learn patterns for realistic data generation.
- **Project scaffolding:** "Claude, create a basic Shiny app structure with modules" - the "getting started" friction is eliminated. You can immediately start on the interesting parts.
- **Documentation:** Claude drafts README files and vignettes that you review and refine.
- **Test data:** Creating edge cases and test scenarios becomes trivial.

This isn't about becoming dependent on AIâ€”it's about using AI to accelerate the learning process by increasing your exposure to different R patterns and approaches.
:::


---

## Mistake #1: Package Confusion {.smaller}

**Claude doesn't read the docsâ€”just like you when you're rushing**

::: {.incremental}
- **What happened:** Asked Claude about `{shinyfa}` â†’ it hallucinated "Font Awesome icons"
- **The real error:** Like installing a package and guessing without reading vignettes/examples
- **It's not just new packages:** Even with {ggplot2}, Claude confuses function arguments
- **Why this happens:** You're experienced, busy, assume things should come easy, so you circumvent
- **The lesson:** This forces you to **actually read documentation** and verify behavior
- **Fix strategy:** Feed Claude the documentation URL, then it self-corrects
:::

::: {.fragment}
**This mistake makes you better at evaluating package quality and knowing where good docs live.**
:::

::: {.notes}
**The Package Confusion Problem: "Not Reading the Docs"**

The {shinyfa} hallucination is documented in CLAUDE.md. Claude assumed from the package name it must be about Font Awesome icons and confidently generated completely wrong example code. **This is exactly what a human developer does when they install a package and start guessing without reading the vignette or examples.**

But here's the key insight: **this happens with mature packages too.** Even with {ggplot2}, Claude will confuse function arguments, mix up geom parameters, or suggest deprecated approaches. It's not just "new packages are risky"â€”Claude can hallucinate about ANY package if it doesn't have current context.

**Why does this happen to humans?** You're really experienced. You've used hundreds of R packages. You're busy. You think "Hey, I'm good at this, this other thing should come really easy." So you circumvent the fundamentalsâ€”you skip the vignette, skim the examples, and start coding. Then you hit errors because you assumed instead of verified.

**What this teaches you:** You MUST verify package behavior. Feed Claude documentation URLs: "Read the shinyfa docs at https://dalyanalytics.github.io/shinyfa/" Then Claude self-corrects. This forces you to know WHERE the good documentation lives and HOW to read it critically. You become better at evaluating package quality and understanding what's actually possible.

**The skill you build:** Systematic verification. Don't assumeâ€”verify. This applies whether you're using AI or coding yourself.
:::

---

## Mistake #2: Data Structure Assumptions {.smaller}

**Claude assumes instead of checkingâ€”sound familiar?**

::: {.incremental}
- **What Claude does:** Assumes column names, data types, relationships
- **Example:** Used `avilist_global` (doesn't exist) instead of `avilist_2025`
- **Example:** Assumed lowercase `order_name` when actual column is `Order`
- **Example:** Infers connections between columns instead of asking for lookup tables
- **Why this happens:** Experience breeds assumptions; you skip verification when busy
- **The lesson:** Use **mcptools** to give Claude actual R session context
- **Fix strategy:** `names(data)`, `str(data)`, or let mcptools read your environment
:::

::: {.fragment}
**This mistake teaches you proper data inspection habitsâ€”skills you use constantly.**
:::

::: {.notes}
**Data Structure Assumptions: Why mcptools is Essential**

Claude LOVES to assume things about your data:
- Assumes column names without checking (`order_name` vs `Order`)
- Assumes dataset names (`avilist_global` vs `avilist_2025`)
- Assumes data types (factor vs character, Date vs POSIXct)
- Assumes relationships between columns instead of asking for lookup tables

**Why does this happen to humans?** You've worked with similar data before. You're experienced. You assume this new dataset follows the same patterns. You're busy, so you skip the basic inspection step. Then you hit "column not found" errors because you assumed instead of checked.

**The mcptools solution:** When you use MCP tools like mcptools, Claude can actually READ your R session. It can see `names(your_data)`, check `str(your_data)`, understand what objects exist. This dramatically reduces hallucination because Claude has actual context instead of assumptions.

**What this teaches you:** How to properly inspect data structures. When Claude makes wrong assumptions, you learn to immediately check: `names(data)`, `str(data)`, `class(column)`, `unique(column)`. These debugging habits make you a better data scientist.

**The deeper lesson:** Providing explicit context (a lookup table) is better than letting Claude (or any developer) infer relationships from content. Making assumptions explicit prevents errors.

**The skill you build:** Rigorous data inspection and explicit context over implicit assumptions.
:::

---

## Mistake #3: Over-Abstraction {.smaller}

**Why is Claude (or you) always doing it the hard way?**

::: {.incremental}
- **Claude's tendency:** Always reaches for complex solutions first
- **Example:** Tried 3 different Sankey packages with hallucinated functions
- **Example:** Creates nested functions when a simple dplyr chain works
- **Why this happens:** You want to show expertise, build "proper" systems, over-engineer
- **The lesson:** Simple is better. Ask "Why are you doing it the hard way?"
- **Fix strategy:** Ask for multiple options, choose the simplest that works
:::

::: {.fragment}
**This mistake teaches you that simplicity is a skillâ€”recognizing unnecessary complexity.**
:::

::: {.notes}
**Over-Abstraction: "Why Are You Doing It The Hard Way?"**

Claude has a STRONG tendency to over-engineer solutions:
- Tried 3 different Sankey packages with hallucinated functions when HTML/CSS was simpler
- Creates nested helper functions when a single dplyr chain is clearer
- Reaches for complex packages when base R works fine
- Suggests class systems when a simple list would do

**Why does this happen to humans?** You want to demonstrate expertise. You want to build "proper" systems with abstraction and reusability. You've learned best practices about DRY (Don't Repeat Yourself) and you over-apply them. Sometimes the simple solution feels too simpleâ€”like you're not being professional enough.

**I now ask Claude directly:** "Why are you doing it the hard way? Show me the simplest solution."

**What this teaches you:** Simplicity is a skill. The ability to recognize when a solution is unnecessarily complex comes from seeing LOTS of complex solutions and learning to reject them. Each time Claude over-abstracts, you practice simplifying. Each time you ask for multiple options, you practice evaluating trade-offs.

**The skill you build:** Choosing appropriate complexity. Not every problem needs a framework. Sometimes a simple dplyr chain beats a custom function. Sometimes HTML/CSS beats a complex R package. Simplicity when possible, complexity when necessary.
:::

---

## Building Better Prompts from Mistakes {.smaller}

**Each mistake pattern teaches you how to redirect Claude (and yourself)**

::: {.incremental}
- **Package confusion** â†’ Feed documentation links upfront
- **Data assumptions** â†’ Use mcptools, provide `str(data)` output, give lookup tables
- **Over-abstraction** â†’ Ask for multiple approaches, request "simplest solution"
:::

::: {.fragment}
**Learning at Scale:** You encounter these patterns 10x/day instead of 1x/week. Each failure refines your prompting skills AND your R intuition.
:::

::: {.fragment}
**You're not becoming dependentâ€”you're becoming a better technical leader who knows how to redirect when things go wrong.**
:::

::: {.notes}
**The Meta-Lesson: Building Better Prompts**

Each mistake category teaches you how to prompt better:
- **Package confusion** â†’ Feed documentation links upfront
- **Data assumptions** â†’ Use mcptools, provide `str(data)` output, give lookup tables
- **Over-abstraction** â†’ Ask for multiple approaches, request "simplest solution"

**Learning at Scale:** The volume advantage means you encounter these mistake patterns FASTER than traditional development. Instead of one careful implementation per week, you see 10 attempts per day. Each failure refines your prompting skills AND your R intuition. You're not becoming dependentâ€”you're becoming a better technical leader who knows how to redirect when things go wrong.

This is exactly what Part 3 is about: using AI-assisted development to accelerate learning through high-volume pattern recognition, not to avoid learning.
:::

---

## ðŸ”‘ The Art of the Practice {.smaller}

**Skill development is a systematic approachâ€”research, analysis, consistent action**

::: {.incremental}
- **Not about the final product alone** â†’ It's about the process of getting there
- **Research & Analysis** â†’ Understanding patterns, learning from mistakes, building intuition
- **Consistent Action** â†’ High-volume iteration, failing fast, course-correcting
- **Achieving Mastery** â†’ Through deliberate practice and pattern recognition
- **Personal Growth** â†’ Overcoming challenges, maintaining motivation, staying disciplined
:::

::: {.fragment}
**AI-assisted development accelerates the practice by increasing volumeâ€”but the discipline of learning is still yours.**
:::

::: {.notes}
**The Art of the Practice: Systematic Skill Development**

The "art of the practice" refers to a systematic approach to skill development, whether in creative fields like visual arts or music, or in technical areas like R development and leadership. It goes beyond just the final product to encompass research, analysis, and consistent action to achieve mastery and personal growth. This involves understanding and applying strategies to improve skills, maintain motivation, and overcome challenges.

**Research & Analysis:** In Part 3, we've covered how to learn from Claude's mistakesâ€”package confusion, data assumptions, over-abstraction. This is the research and analysis phase. You're not just fixing errors; you're understanding WHY they happen and what patterns they reveal about effective R development.

**Consistent Action:** The volume advantage of AI-assisted development (10 attempts/day vs 1/week) is the consistent action. You're practicing constantly, iterating rapidly, building muscle memory for recognizing good code vs bad code, simple vs over-complex, verified vs assumed.

**Achieving Mastery:** Mastery comes from pattern recognition, and pattern recognition requires exposure to lots of patterns. By encountering Claude's mistakes at scale, you're accelerating your path to mastery. You're learning what good documentation looks like, how to inspect data structures properly, when to choose simplicity over abstraction.

**Personal Growth & Overcoming Challenges:** The discipline of the practice is staying engaged when Claude makes mistakes, not giving up when errors repeat, maintaining curiosity about WHY something failed rather than just fixing it. The temptation with AI is to become passiveâ€”just accept what it generates. The art of the practice is staying active, critical, and intentional.

**Maintaining Motivation:** The professional joy we discussed in Part 1 (client work, technical growth, life balance, community) is what maintains motivation. The ruthless solutions-focus from Part 2 is what keeps you disciplined. The learning through volume from Part 3 is what builds your skills systematically.

**The Key Insight:** AI-assisted development accelerates the practice by increasing volume and speed of iteration. But it doesn't replace the discipline of learning. You still need to:
- Read the documentation (don't assume)
- Inspect your data structures (don't infer)
- Choose simplicity (don't over-engineer)
- Stay curious about failures (don't just fix and move on)

This is systematic skill developmentâ€”using AI as a tool to practice more, fail faster, and learn deeper. The art is in how you engage with the process, not just the output you produce.
:::

# Conclusion: Human In/On the Loop

## Your AI Values Exercise

Before your next AI-assisted project, write down:

1. **What I will always do myself**
2. **What AI can help me with**
3. **What I need to understand deeply**
4. **What I'm comfortable delegating**

**This clarity prevents AI-Assisted development from going out of bounds**

::: {.notes}
Before you start working with AI tools like Claude Code, take time to establish your personal values and boundaries. This isn't about restricting AI useâ€”it's about using it intentionally.

**What I will always do myself:** For me, this includes final code review, client communication, architectural decisions, and anything security-sensitive. These are areas where my expertise and judgment are irreplaceable.

**What AI can help me with:** Boilerplate code, documentation, unfamiliar packages, repetitive transformations, initial implementations. These are areas where AI accelerates my work without compromising quality.

**What I need to understand deeply:** The business logic, the data architecture, the deployment pipeline, how everything connects. Even if AI writes the code, I need to understand it well enough to maintain and extend it.

**What I'm comfortable delegating:** The implementation details, the syntax lookup, the initial scaffolding. These are tasks that AI handles well and that don't require my deep expertise.

This exercise creates guardrails that help you work with AI effectively without losing technical leadership or creating maintenance nightmares.
:::

---

## Hand on the Wheel

**Key Principle:** AI accelerates; you steer.

::: {.incremental}
- **Let AI generate** the boilerplate, the repetitive code, the initial structure
- **You maintain** the architecture, the business logic, the critical decisions
- **Review everything** like you're mentoring an intern
- **Refactor freely** to match your style and standards
- **Test thoroughly** because AI doesn't understand your edge cases
:::

---

## The Core Philosophy

**AI doesn't replace expertise.**

**It amplifies it.**

<br>

::: {.incremental}
- You remain the architect
- You maintain the standards
- You own the relationships
- You deliver the value
:::

---

## Final Thoughts 

> "When AI frees up your mental bandwidth, you don't get lazyâ€”you get strategic."

<br>

**Stay in your lane.**

**Keep your hand on the wheel.**

**Build with confidence.**

---

## Thank You {.center}

![](images/horizontal-logo.png){width=60% fig-align="center"}

**Questions?**

<br>

Contact: [jasmine@dalyanalytics.com]

GitHub: [@jasdumas]

Website: [dalyanalytics.com]

::: {.notes}
Thank you all for your time. I'm happy to take questions about AI-assisted development, R workflows, or anything else we've covered today.
:::
